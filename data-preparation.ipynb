{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize files by writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = 'data'\n",
    "xml_dir = os.path.join(data_dir, 'xml')\n",
    "lines_dir = os.path.join(data_dir, 'lines')\n",
    "output_dir = os.path.join(data_dir, 'writers')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse XML and get author ID\n",
    "def get_author_id(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    writer_id = root.attrib.get('writer-id')\n",
    "    return writer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through subdirectories in lines/\n",
    "for subdir, _, _ in os.walk(lines_dir):\n",
    "    for file_name in os.listdir(subdir):\n",
    "        if file_name.endswith('.png'):\n",
    "            \n",
    "            # Construct the corresponding XML file path\n",
    "            base_name = '-'.join(file_name.split('-')[:-1]) + '.xml'\n",
    "            xml_file = os.path.join(xml_dir, base_name)\n",
    "            \n",
    "            if os.path.exists(xml_file):\n",
    "                # Get author ID from XML file\n",
    "                author_id = get_author_id(xml_file)\n",
    "                \n",
    "                author_dir = os.path.join(output_dir, author_id)\n",
    "                os.makedirs(author_dir, exist_ok=True)\n",
    "                \n",
    "                src_image_path = os.path.join(subdir, file_name)\n",
    "                dst_image_path = os.path.join(author_dir, file_name)\n",
    "                shutil.move(src_image_path, dst_image_path)\n",
    "                print(f'Moved {src_image_path} to {dst_image_path}')\n",
    "            else:\n",
    "                print(f'XML file {xml_file} not found for image {file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Inputs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "img_size = (105, 105)  # Size to resize images to\n",
    "data_dir = os.path.join('data', 'writers') # Directory with author subdirectories\n",
    "pairs_per_author = 10  # Number of pairs to generate per author\n",
    "\n",
    "# Functions\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if not filename.endswith('.png'):\n",
    "            continue\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = load_img(img_path, target_size=img_size, color_mode='grayscale')\n",
    "        img = img_to_array(img) / 255.0\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def create_pairs():\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    authors = os.listdir(data_dir)\n",
    "    \n",
    "    for author in authors:\n",
    "        author_folder = os.path.join(data_dir, author)\n",
    "        if os.path.isdir(author_folder):\n",
    "            images = load_images_from_folder(author_folder)\n",
    "            num_images = len(images)\n",
    "            \n",
    "            # Generate positive pairs\n",
    "            for _ in range(pairs_per_author):\n",
    "                img1, img2 = random.sample(images, 2)\n",
    "                pairs.append((img1, img2))\n",
    "                labels.append(1)\n",
    "            \n",
    "            # Generate negative pairs\n",
    "            for _ in range(pairs_per_author):\n",
    "                other_author = random.choice([a for a in authors if a != author])\n",
    "                other_author_folder = os.path.join(data_dir, other_author)\n",
    "                if not os.path.isdir(other_author_folder):\n",
    "                    continue\n",
    "                other_images = load_images_from_folder(other_author_folder)\n",
    "                img1 = random.choice(images)\n",
    "                img2 = random.choice(other_images)\n",
    "                pairs.append((img1, img2))\n",
    "                labels.append(0)\n",
    "    \n",
    "    return pairs, labels\n",
    "\n",
    "def save_arrays(X_train_1, X_train_2, labels_train, X_val_1, X_val_2, labels_val, prefix='dataset'):\n",
    "    input_folder = os.path.join('data', 'tf_inputs')\n",
    "    \n",
    "    # Ensure the input folder exists\n",
    "    os.makedirs(input_folder, exist_ok=True)\n",
    "    \n",
    "    np.save(os.path.join(input_folder, f'{prefix}_X_train_1.npy'), X_train_1)\n",
    "    np.save(os.path.join(input_folder, f'{prefix}_X_train_2.npy'), X_train_2)\n",
    "    np.save(os.path.join(input_folder, f'{prefix}_labels_train.npy'), labels_train)\n",
    "    np.save(os.path.join(input_folder, f'{prefix}_X_val_1.npy'), X_val_1)\n",
    "    np.save(os.path.join(input_folder, f'{prefix}_X_val_2.npy'), X_val_2)\n",
    "    np.save(os.path.join(input_folder, f'{prefix}_labels_val.npy'), labels_val)\n",
    "    \n",
    "    print(f'Data saved in \"{input_folder}\" with prefix \"{prefix}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Error: The pairs or labels array is empty.\n",
      "X_train_1 shape: (0,)\n",
      "X_train_2 shape: (0,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train_1 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train_1\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train_2 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train_2\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlabels_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_val_1 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_val_1\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_val_2 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_val_2\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "pairs, labels = create_pairs()\n",
    "\n",
    "pairs = np.array(pairs)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split into training and validation sets\n",
    "pairs_train, pairs_val, labels_train, labels_val = train_test_split(pairs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_1 = np.array([pair[0] for pair in pairs_train])\n",
    "X_train_2 = np.array([pair[1] for pair in pairs_train])\n",
    "X_val_1 = np.array([pair[0] for pair in pairs_val])\n",
    "X_val_2 = np.array([pair[1] for pair in pairs_val])\n",
    "\n",
    "\n",
    "print(f'X_train_1 shape: {X_train_1.shape}')\n",
    "print(f'X_train_2 shape: {X_train_2.shape}')\n",
    "print(f'labels_train shape: {labels_train.shape}')\n",
    "print(f'X_val_1 shape: {X_val_1.shape}')\n",
    "print(f'X_val_2 shape: {X_val_2.shape}')\n",
    "print(f'labels_val shape: {labels_val.shape}')\n",
    "\n",
    "# Save data\n",
    "save_arrays(X_train_1, X_train_2, labels_train, X_val_1, X_val_2, labels_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecs174",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
